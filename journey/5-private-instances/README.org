#+TITLE: A journey with Terraform on OVH Cloud (part 6)
#+AUTHOR: yann degat
#+EMAIL: yann.degat@corp.ovh.com

* Objective

This document is the sixth part of a [[../0-simple-terraform/README.md][step by step guide]] on how to use 
the [[https://terraform.io][Hashicorp Terraform]] tool with [[https://www.ovh.com/fr/public-cloud/instances/][OVH Cloud]]. It will help you create 
openstack private instances on the region of your choice and connect
to it via a simple bastion host.


* Pre requisites

Please refer to the pre requisites paragraph of the [[../0-simple-terraform/README.md][first part]] of this guide.


* In pratice: OVH cloud: private instances

Here's how to boot private instances on OVH public cloud using terraform:

We'll start with a basic terraform setup with a remote state backend,
openstack provider targeting our region, a keypair and a security group:

#+BEGIN_SRC terraform :eval never-export :tangle main.tf
# define a remote state backend on swift
terraform {
  backend "swift" {
    container = "demo-public-instance"
  }
}

# configure your openstack provider to target the region of your choice
provider "openstack" {
  region = "${var.region}"
}

# Import Keypair by inlining your ssh public key using terraform interpolation 
# primitives (https://www.terraform.io/docs/configuration/interpolation.html)
resource "openstack_compute_keypair_v2" "keypair" {
  name       = "${var.name}"
  public_key = "${file("~/.ssh/id_rsa.pub")}"
}

# get NATed IP to allow ssh only from terraform host
data "http" "myip" {
  url = "https://api.ipify.org"
}

# create the security group to which the instances & ports will be associated
resource "openstack_networking_secgroup_v2" "sg" {
  name        = "${var.name}_ssh_sg"
  description = "${var.name} security group"
}

# allow remote ssh connection only for terraform host
resource "openstack_networking_secgroup_rule_v2" "in_traffic_ssh" {
  direction         = "ingress"
  ethertype         = "IPv4"
  protocol          = "tcp"
  remote_ip_prefix  = "${trimspace(data.http.myip.body)}/32"
  port_range_min    = 22
  port_range_max    = 22
  security_group_id = "${openstack_networking_secgroup_v2.sg.id}"
}

# allow egress traffic worldwide
resource "openstack_networking_secgroup_rule_v2" "egress_instances" {
  direction         = "egress"
  ethertype         = "IPv4"
  remote_ip_prefix  = "0.0.0.0/0"
  security_group_id = "${openstack_networking_secgroup_v2.sg.id}"
}
#+END_SRC

Next, as we want to boot instances in a private subnet, we have to setup
the private network:

#+BEGIN_SRC terraform :eval never-export :tangle main.tf
# private network (be sure a vrack has been attached to your openstack tenant
# otherwise this resource will fail)
resource "openstack_networking_network_v2" "net" {
  name           = "${var.name}"
  admin_state_up = "true"
}

# create the subnet in which the instances will be spawned
resource "openstack_networking_subnet_v2" "subnet" {
  network_id = "${openstack_networking_network_v2.net.id}"
  cidr       = "${var.cidr}"
  ip_version = 4

  # dhcp is required if you want to be able to retrieve metadata from
  # the 169.254.169.254 because the route is pushed via dhcp
  enable_dhcp = true

  # this attribute is set for doc purpose only : GW are not used within OVH
  # network as it's a layer 2 network. Instead, you have to setup your
  # routes properly on each instances
  no_gateway = true

  # ovh dns, then google dns. order matters
  dns_nameservers = ["213.186.33.99", "8.8.8.8"]

  allocation_pools {
    # you can subdivise your network with terraform interpolation primitives
    # be aware that a dhcp agent will take one IP within the allocation pool
    start = "${cidrhost(var.cidr,2)}"
    end   = "${cidrhost(var.cidr,-2)}"
  }
}
#+END_SRC

Now that we have the network properly setup, we can spawn our instances, with their 
associated ports:

#+BEGIN_SRC terraform :eval never-export :tangle main.tf
# create an anti-affinity server group.
# WARNING: You can't boot more than 5
# servers in one server group
resource "openstack_compute_servergroup_v2" "group" {
  name     = "${var.name}"
  policies = ["anti-affinity"]
}

# create subnet ports that will be attached to instances
resource "openstack_networking_port_v2" "ports" {
  count          = "${var.count}"
  name           = "${var.name}_${count.index}"
  network_id     = "${openstack_networking_network_v2.net.id}"
  admin_state_up = "true"

  fixed_ip {
    subnet_id = "${openstack_networking_subnet_v2.subnet.id}"
  }
}

resource "openstack_compute_instance_v2" "instances" {
  count           = "${var.count}"
  name            = "${var.name}_${count.index}"
  image_name      = "Centos 7"
  flavor_name     = "s1-8"
  key_pair        = "${openstack_compute_keypair_v2.keypair.name}"
  security_groups = ["${openstack_networking_secgroup_v2.sg.name}"]

  network {
    port           = "${element(openstack_networking_port_v2.ports.*.id, count.index)}"
    access_network = true
  }

  scheduler_hints {
    group = "${openstack_compute_servergroup_v2.group.id}"
  }
}
#+END_SRC

Nothing different from the public instances example, but:
- now we're creating ports on our own private network, referencing our subnet.
  We could have created multiple subnets within the same network. the ~fixed_ip~
  block shows how to target a specific subnet.
- we don't associate a security group on these instances because security groups
  are ineffective on Vrack networks as they are L2 networks. Meaning you'll have to 
  handle iptables rules if you want to restrict network access within your instances
  on your private networks


We're almost done. The last thing we want to do is access our private boxes through 
a secured connection. To achieve this, we'll create a bastion host with 2 network 
interface: one in the public network with associated security rules, one in the private network.

#+BEGIN_SRC terraform :eval never-export :tangle main.tf

####
#  bastion host
###
# use a data source to retrieve Ext-Net network id for your target region
data "openstack_networking_network_v2" "ext_net" {
  name      = "Ext-Net"
  tenant_id = ""
}

# create a port before the instances allows you
# to keep your IP when you taint an instance
resource "openstack_networking_port_v2" "bastion_public_port" {
  name               = "${var.name}_bastion_pub"
  network_id         = "${data.openstack_networking_network_v2.ext_net.id}"
  admin_state_up     = "true"

  # attach a security group on the public port to filter access
  security_group_ids = ["${openstack_networking_secgroup_v2.sg.id}"]
}

# create a port before the instances allows you
# to keep your IP when you taint an instance
resource "openstack_networking_port_v2" "bastion_private_port" {
  name           = "${var.name}_bastion_priv"
  network_id     = "${openstack_networking_network_v2.net.id}"
  admin_state_up = "true"

  fixed_ip {
    subnet_id = "${openstack_networking_subnet_v2.subnet.id}"
  }
}

# launch the bastion host
resource "openstack_compute_instance_v2" "bastion" {
  name            = "${var.name}_bastion"
  image_name      = "Centos 7"
  flavor_name     = "s1-2"
  key_pair        = "${openstack_compute_keypair_v2.keypair.name}"
  security_groups = ["${openstack_networking_secgroup_v2.sg.name}"]

  # Inject userdata into the bastion host to automatically
  # bring both network interfaces on boot
  user_data = <<USERDATA
#cloud-config
# add ncat to allow ssh proxy commands
runcmd:
 - yum install -y nmap-ncat
# enable eth1
bootcmd:
 - dhclient eth1
USERDATA

  # attach the private port on eth0
  network {
    port = "${openstack_networking_port_v2.bastion_private_port.id}"
  }

  # attach the public port on eth1
  network {
    port           = "${openstack_networking_port_v2.bastion_public_port.id}"
    access_network = true
  }
}
#+END_SRC


Ok. We're done with the setup. Let's try to apply it:

#+BEGIN_SRC bash :session *journey* :results output pp  :eval never-export
source ~/openrc.sh
terraform init
terraform apply -auto-approve
#+END_SRC

#+BEGIN_EXAMPLE bash
Initializing the backend...

Successfully configured the backend "swift"! Terraform will automatically
use this backend unless the backend configuration changes.
...
data.http.myip: Refreshing state...
data.openstack_networking_network_v2.ext_net: Refreshing state...
openstack_networking_secgroup_v2.sg: Creating...
  description: "" => "demo-private-instances security group"
  name:        "" => "demo-private-instances_ssh_sg"
  region:      "" => "<computed>"
  tenant_id:   "" => "<computed>"
openstack_networking_network_v2.net: Creating...
  admin_state_up:            "" => "true"
  availability_zone_hints.#: "" => "<computed>"
  name:                      "" => "demo-private-instances"
  region:                    "" => "<computed>"
  shared:                    "" => "<computed>"
  tenant_id:                 "" => "<computed>"
...
openstack_compute_instance_v2.instances[1]: Creation complete after 25s (ID: 27b6b72f-8754-4a52-b3e4-36fe959b19df)
openstack_compute_instance_v2.instances[0]: Creation complete after 25s (ID: 76fc8751-677b-42ac-8481-1015245c71de)
openstack_compute_instance_v2.instances[2]: Creation complete after 25s (ID: 7ecad3f0-61e5-4ffe-80fd-6fa0d07eeb34)
openstack_compute_instance_v2.bastion: Still creating... (30s elapsed)
openstack_compute_instance_v2.bastion: Still creating... (40s elapsed)
openstack_compute_instance_v2.bastion: Still creating... (50s elapsed)
openstack_compute_instance_v2.bastion: Still creating... (1m0s elapsed)
openstack_compute_instance_v2.bastion: Still creating... (1m10s elapsed)
openstack_compute_instance_v2.bastion: Still creating... (1m20s elapsed)
openstack_compute_instance_v2.bastion: Creation complete after 1m28s (ID: 2e4f8811-f229-45cf-b4e9-edc7ca51c3c9)

Apply complete! Resources: 16 added, 0 changed, 0 destroyed.

Outputs:

helper = You can now connect to your instances:
   $ ssh -J centos@a.b.c.d centos@10.0.0.7
   $ ssh -J centos@a.b.c.d centos@10.0.0.11
   $ ssh -J centos@a.b.c.d centos@10.0.0.10
#+END_EXAMPLE  


How fun! You can now ssh into your centos box by pasting the output helper.

#+BEGIN_EXAMPLE bash
ssh -J centos@a.b.c.d centos@10.0.0.7
The authenticity of host 'a.b.c.d (a.b.c.d)' can't be established.
ECDSA key fingerprint is SHA256:...
ECDSA key fingerprint is MD5:...
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added 'a.b.c.d' (ECDSA) to the list of known hosts.
The authenticity of host '10.0.0.7 (<no hostip for proxy command>)' can't be established.
ECDSA key fingerprint is SHA256:...
ECDSA key fingerprint is MD5:...
Are you sure you want to continue connecting (yes/no)? yes
Warning: Permanently added '10.0.0.7' (ECDSA) to the list of known hosts.
[centos@demo-private-instances-0 ~]$ ping 10.0.0.11
PING 10.0.0.11 (10.0.0.11) 56(84) bytes of data.
64 bytes from 10.0.0.11: icmp_seq=1 ttl=64 time=1.51 ms
64 bytes from 10.0.0.11: icmp_seq=2 ttl=64 time=0.458 ms
^C
--- 10.0.0.11 ping statistics ---
2 packets transmitted, 2 received, 0% packet loss, time 1001ms
rtt min/avg/max/mdev = 0.458/0.988/1.519/0.531 ms
[centos@demo-private-instances-0 ~]$
#+END_EXAMPLE

Youhou! Super great!

But wait... have you noticed that your instances don't have access to internet?
That's because they don't have any route to any Internet Gateway. That's a topic
for our next journey introducing OVH terraform modules.

Again, don't forget to destroy your instance once done:
#+BEGIN_SRC bash :session *journey* :results output pp  :eval never-export
source ~/openrc.sh
terraform destroy -force
...
#+END_SRC

#+BEGIN_EXAMPLE bash
...
openstack_compute_instance_v2.bastion: Destruction complete after 10s
openstack_networking_port_v2.bastion_public_port: Destroying... (ID: 9db180c7-e0d7-4542-bd6c-f4b1607e06f2)
openstack_networking_port_v2.bastion_private_port: Destroying... (ID: d0339ee6-faf0-4698-8c34-24e29cf39fb0)
openstack_compute_instance_v2.instances[1]: Destruction complete after 10s
openstack_compute_instance_v2.instances[2]: Destruction complete after 10s
openstack_compute_instance_v2.instances[0]: Destruction complete after 10s
openstack_compute_servergroup_v2.group: Destroying... (ID: 2589e06d-7114-4a24-b3a7-eeadbf934de3)
openstack_compute_keypair_v2.keypair: Destroying... (ID: demo-private-instances)
openstack_networking_port_v2.ports[0]: Destroying... (ID: ebb441c3-d367-4451-b3a3-8ae7939668ba)
openstack_networking_port_v2.ports[1]: Destroying... (ID: efc77118-4156-4fee-a929-c5b205dfa7ed)
openstack_networking_port_v2.ports[2]: Destroying... (ID: 01f15fda-43c7-4837-be8c-ca6590d43f0a)
openstack_compute_keypair_v2.keypair: Destruction complete after 0s
openstack_compute_servergroup_v2.group: Destruction complete after 0s
openstack_networking_port_v2.bastion_public_port: Destruction complete after 9s
openstack_networking_secgroup_v2.sg: Destroying... (ID: 4a9c35ef-4339-4bec-bc33-c85e2b19b9ef)
openstack_networking_port_v2.bastion_private_port: Destruction complete after 9s
openstack_networking_port_v2.ports[1]: Destruction complete after 9s
openstack_networking_port_v2.ports[2]: Destruction complete after 9s
openstack_networking_port_v2.ports[0]: Destruction complete after 9s
openstack_networking_subnet_v2.subnet: Destroying... (ID: a5b391ca-8f90-4123-ba08-23f15f5822c6)
openstack_networking_secgroup_v2.sg: Destruction complete after 8s
openstack_networking_subnet_v2.subnet: Destruction complete after 9s
openstack_networking_network_v2.net: Destroying... (ID: 7ec74941-7183-41eb-8e89-64ea706dd731)
openstack_networking_network_v2.net: Destruction complete after 9s

Destroy complete! Resources: 16 destroyed.
#+END_EXAMPLE  


* Going Further


Next time we'll introduce OVH terraform modules.

See you on [[../6-intro-modules/README.md][the seventh step]] of our journey.
